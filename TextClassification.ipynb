{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "class Tokenizer():\n",
        "    def __init__(self):\n",
        "        self.wordMap = {}\n",
        "        self.wordMap2 = {}\n",
        "\n",
        "    def format_text(self, t):\n",
        "      t = t.replace(\".\", \"\").replace(\"?\", \"\").replace(\"!\", \"\")\n",
        "      return t\n",
        "\n",
        "    def build_vocab(self,file,fromWeb=False):\n",
        "        self.wordMap = {}\n",
        "        splitted = None\n",
        "        if not fromWeb:\n",
        "            with open(file, \"r\") as f:\n",
        "                text = f.read()\n",
        "                text = self.ormat_text\n",
        "                splitted = text.split(' ')\n",
        "        else:\n",
        "            response = requests.get(file)\n",
        "            response.raise_for_status()\n",
        "            response.text = self.format_text(response.text)\n",
        "            splitted = response.text.split(' ')\n",
        "\n",
        "        for i in range(len(splitted)):\n",
        "            if splitted[i].lower() not in self.wordMap:\n",
        "\n",
        "              self.wordMap[splitted[i].lower()] = i\n",
        "              self.wordMap2[i] = splitted[i].lower()\n",
        "\n",
        "    def build_vocab_var(self, texts):\n",
        "      combined_text = \"\"\n",
        "      for j,text in enumerate(texts):\n",
        "        combined_text += text\n",
        "\n",
        "      combined_text = self.format_text(combined_text)\n",
        "      splitted = combined_text.split(' ')\n",
        "      for i in range(len(splitted)):\n",
        "        if splitted[i].lower() not in self.wordMap:\n",
        "          self.wordMap[splitted[i].lower()] = i\n",
        "          self.wordMap2[i] = splitted[i].lower()\n",
        "\n",
        "\n",
        "    def addToken(self, word):\n",
        "        if word not in self.wordMap:\n",
        "            self.wordMap[word] = len(self.wordMap)\n",
        "            self.wordMap2[len(self.wordMap)] = word\n",
        "\n",
        "    def encode(self, text):\n",
        "        text = text.lower()\n",
        "        text = self.format_text(text)\n",
        "\n",
        "        encoded_list = []\n",
        "        splitted_text = text.split()\n",
        "        for token in splitted_text:\n",
        "            encoded_list.append(self.wordMap[token])\n",
        "        return encoded_list\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        decoded_list = []\n",
        "        for token in tokens:\n",
        "            decoded_list.append(self.wordMap2[token])\n",
        "        return decoded_list\n",
        "\n",
        "    def test(self,url):\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()\n",
        "        print(response.text)"
      ],
      "metadata": {
        "id": "LQGI202BF6EA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"priyangshumukherjee/mental-health-text-classification-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnXUfr6J7uGy",
        "outputId": "6bf29fd6-d22f-4fdb-856f-d9564041d6e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'mental-health-text-classification-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/mental-health-text-classification-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data_csv = pd.read_csv(path + \"/mental_health_combined_test.csv\")\n",
        "print(data_csv[\"text\"][0])\n",
        "print(data_csv[\"status\"][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-5SAP9z7zVC",
        "outputId": "e9ad1028-8cb1-4ced-a213-b32dbab621dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don't understand whats wrong with me. i don't know why i freak out sometimes. like right now i'm just laying in bed nothing is happening but i can't keep the tears running from down my face. it's stupid. i'm honestly fine nothing is wrong. why on earth am i like this?\n",
            "Anxiety\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#label map\n",
        "unique_labels = data_csv[\"status\"].unique()\n",
        "label_map = {}\n",
        "for i, texts in enumerate(unique_labels):\n",
        "  label_map[texts] = i\n",
        "label_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySzFPKQ_8eJY",
        "outputId": "866ccca2-5cf1-48ac-c4bf-c4fdabe4b469"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Anxiety': 0, 'Depression': 1, 'Normal': 2, 'Suicidal': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_csv[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uxj0M8sU8_RY",
        "outputId": "4df7cb0a-5199-49e1-9b65-91dfe81d5697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "992"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = data_csv[\"text\"]\n",
        "status = data_csv[\"status\"]\n",
        "\n",
        "train_texts = texts[:700]\n",
        "test_texts = texts[700:].reset_index(drop=True)\n",
        "print(train_texts[0])\n",
        "print(test_texts[0])\n",
        "\n",
        "train_status = status[:700]\n",
        "test_status = status[700:].reset_index(drop=True)\n",
        "print(train_status[0])\n",
        "print(test_status[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D1ki_9s9EID",
        "outputId": "a54733b8-c9d7-4517-b83c-086b8f339896"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i don't understand whats wrong with me. i don't know why i freak out sometimes. like right now i'm just laying in bed nothing is happening but i can't keep the tears running from down my face. it's stupid. i'm honestly fine nothing is wrong. why on earth am i like this?\n",
            "See ya dudes and dudettes... i am no longer part of the club :( officially 20 now... ill see yall in 93 years!\n",
            "Anxiety\n",
            "Normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.wordMap.clear()\n",
        "tokenizer.wordMap2.clear()\n",
        "tokenizer.build_vocab_var(texts)"
      ],
      "metadata": {
        "id": "33RNABABAPzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.wordMap[\"i\"]\n",
        "#tokenizer.wordMap2[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_prhXEbxhckA",
        "outputId": "85559174-5202-4bd4-cd3c-4c3fab701c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.wordMap)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqXKiUxsEb_l",
        "outputId": "11b7c9c2-78a8-47f6-e560-fb4797b3769a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13195"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc = tokenizer.encode(train_texts[200])\n",
        "dec = tokenizer.decode(enc)\n",
        "t = ' '.join(dec)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "SKM3UtJCCZ6T",
        "outputId": "c6646a62-9469-40e3-cdbc-23718a617642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"i just got hired for a job that pays pretty well, and the hours are well-suited for me, working about 4-6 hours per day, and i am super happy about it because i quit many jobs because of its long hours, and i hope this one last and that i wouldn't have any attacks at work\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#diffrent tokenizer\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"o200k_base\")\n",
        "e = tokenizer.encode(\"<SOT>\"  + train_texts[0] + \" EOT\")\n",
        "print(e)\n",
        "print(tokenizer.decode(e))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO98s98vGpX7",
        "outputId": "d6db3aa0-8293-4ff4-eeb5-685383bfa453"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[30312, 2824, 29, 72, 4128, 4218, 55993, 8201, 483, 668, 13, 575, 4128, 1761, 4436, 575, 48851, 842, 10069, 13, 1299, 1849, 1954, 49232, 1327, 59127, 306, 3737, 6939, 382, 20230, 889, 575, 8535, 3357, 290, 37095, 6788, 591, 1917, 922, 4950, 13, 4275, 33883, 13, 49232, 39510, 8975, 6939, 382, 8201, 13, 4436, 402, 13440, 939, 575, 1299, 495, 30, 457, 2824]\n",
            "<SOT>i don't understand whats wrong with me. i don't know why i freak out sometimes. like right now i'm just laying in bed nothing is happening but i can't keep the tears running from down my face. it's stupid. i'm honestly fine nothing is wrong. why on earth am i like this? EOT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, tokenizer, texts, status):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.texts = texts\n",
        "    self.status = status\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text = self.texts[idx]\n",
        "    status = label_map[self.status[idx]]\n",
        "\n",
        "    tokenized_text = self.tokenizer.encode(text)\n",
        "\n",
        "    return torch.tensor(tokenized_text, dtype=torch.long), torch.tensor(status, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "ME3alOEh_xeE"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparameters\n",
        "if torch.cuda.is_available():\n",
        "  device = \"cuda\"\n",
        "else:\n",
        "  device = \"cpu\"\n",
        "batch_size = 8\n",
        "embeded_dim = 100\n",
        "hidden_dim = 128\n",
        "output_dim = 4"
      ],
      "metadata": {
        "id": "9EeG0SNcCVlq"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_batch(batch):\n",
        "  text_list, label_list = [], []\n",
        "  for texts, labels in batch:\n",
        "    text_list.append(texts)\n",
        "    label_list.append(labels)\n",
        "\n",
        "  text_padded = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "  labels = torch.tensor(label_list, dtype=torch.long)\n",
        "  return text_padded, labels\n",
        "\n",
        "train_set = TextDataset(tokenizer, train_texts, train_status)\n",
        "test_set = TextDataset(tokenizer, test_texts, test_status)\n",
        "\n",
        "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)\n",
        "train_loader, test_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcmt2caaBYqY",
        "outputId": "f7bf95fe-19bf-4ac4-f175-919986224693"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7eac7e6bb560>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7eab92f9ccb0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ersten Batch inspizieren\n",
        "for texts, labels in train_loader:\n",
        "    print(\"Text batch shape:\", texts.shape)  # (batch_size, sequence_length)\n",
        "    print(\"Label batch shape:\", labels.shape)  # (batch_size,)\n",
        "    print(\"Erste Text-IDs:\", texts[0])\n",
        "    print(\"Erstes Label:\", labels[0])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDfY04dfDHIk",
        "outputId": "4233ae82-8a05-43b0-d4d9-8a0c3ccbec08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text batch shape: torch.Size([8, 199])\n",
            "Label batch shape: torch.Size([8])\n",
            "Erste Text-IDs: tensor([ 30312,   2824,     29,     72,   5141,   4566,   5664,     13,    575,\n",
            "          5141,  75680,    316,   2107,   3823,   5048,     13,    575,   5141,\n",
            "          9791,    575,    673,   8847,     13,    575,   5141,   2447,    306,\n",
            "          3047,     13,    575,   5141,   3778,   6687,    316,    290,  10668,\n",
            "            13,    575,   5141,  24602,  78034,    869,    306,    290,   8709,\n",
            "             0,    665,    481,   6423,    484,     30,   1354,    673,    261,\n",
            "          1058,   1919,    575,  60424,    869,     11,    326,    575,    673,\n",
            "          1299,    392, 173684,  37377,     11,    575,    717,    316,    413,\n",
            "           668,    395,    261,   6062,   8415,  14202,     77,   2163,  18313,\n",
            "           575,   5141,   3778,   6687,    316,  26585,    326,    922,  17715,\n",
            "          7665,    328,    272,  47248,   1373,     13,    575,   5141,   4566,\n",
            "           261,   5277,    575,   4771,  22536,    306,     13,    575,   5141,\n",
            "          4566,   5498,     13,   1261,   1354,    553,  17938,    484,    717,\n",
            "          8883,   1299,    495,     11,    575,   1327,   1008,    575,   5141,\n",
            "          1412,    575,   1458,     13,    538,    481,   1729,    495,     11,\n",
            "           326,    538,    481,   4862, 116248,    634,   2006,   1511,  30664,\n",
            "          1299,    575,   2242,     11,   4843,   4128,   1632,    480,    810,\n",
            "            13,  12764,  42428,    480,    538,    481,    621,   9032,   2824,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0])\n",
            "Erstes Label: tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.n_vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEpeVVoHFtT-",
        "outputId": "ab919c40-ec4e-4cf4-90e8-79deae8a4285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200019"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TextModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embeded_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embeded_dim)\n",
        "    self.lstm = nn.LSTM(embeded_dim, hidden_dim, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    embeded = self.embedding(x)\n",
        "    lstm_out, _ = self.lstm(embeded)\n",
        "    hidden_state = lstm_out[:, -1, :]  # Letzter Zeitschritt der Sequenz\n",
        "    output = self.fc(hidden_state)\n",
        "    return self.sigmoid(output)\n",
        "\n",
        "model = TextModel(tokenizer.n_vocab , embeded_dim, hidden_dim, output_dim).to(device)"
      ],
      "metadata": {
        "id": "ppjNMZouDYnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "QqP6eWY2E000"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for text, label in train_loader:\n",
        "    text, label = text.to(device), label.to(device)\n",
        "\n",
        "    outputs = model(text).squeeze(1)\n",
        "    loss = loss_fn(outputs, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_1TP6eEE_df",
        "outputId": "ff633b81-d9ee-4421-81e9-863527740b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 1.2383\n",
            "Epoch 2/30, Loss: 1.2039\n",
            "Epoch 3/30, Loss: 1.2022\n",
            "Epoch 4/30, Loss: 1.2069\n",
            "Epoch 5/30, Loss: 1.2049\n",
            "Epoch 6/30, Loss: 1.2043\n",
            "Epoch 7/30, Loss: 1.2020\n",
            "Epoch 8/30, Loss: 1.2031\n",
            "Epoch 9/30, Loss: 1.2015\n",
            "Epoch 10/30, Loss: 1.2026\n",
            "Epoch 11/30, Loss: 1.2026\n",
            "Epoch 12/30, Loss: 1.2011\n",
            "Epoch 13/30, Loss: 1.1697\n",
            "Epoch 14/30, Loss: 1.1302\n",
            "Epoch 15/30, Loss: 1.1163\n",
            "Epoch 16/30, Loss: 1.0967\n",
            "Epoch 17/30, Loss: 1.0881\n",
            "Epoch 18/30, Loss: 1.2105\n",
            "Epoch 19/30, Loss: 1.2141\n",
            "Epoch 20/30, Loss: 1.2140\n",
            "Epoch 21/30, Loss: 1.2136\n",
            "Epoch 22/30, Loss: 1.2096\n",
            "Epoch 23/30, Loss: 1.1764\n",
            "Epoch 24/30, Loss: 1.0920\n",
            "Epoch 25/30, Loss: 1.0188\n",
            "Epoch 26/30, Loss: 0.9612\n",
            "Epoch 27/30, Loss: 0.9591\n",
            "Epoch 28/30, Loss: 0.9486\n",
            "Epoch 29/30, Loss: 0.9687\n",
            "Epoch 30/30, Loss: 0.9624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 3\n",
        "text = tokenizer.encode(test_texts[idx])\n",
        "input_tens = torch.tensor(text, dtype=torch.long).unsqueeze(0).to(device)\n",
        "out = model(input_tens)\n",
        "max_index_argmax = out.argmax()\n",
        "print(max_index_argmax)\n",
        "print(label_map[test_status[idx]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v1wwMsYLrXn",
        "outputId": "f356c60b-d9e3-4d38-ceda-585eaddfa386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2, device='cuda:0')\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hier mal mit einem transformer"
      ],
      "metadata": {
        "id": "MMj1L6MXOolt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#more hyperparameters\n",
        "EMBED_DIM = 256\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "d_model = 4\n",
        "NUM_HEADS = 4\n",
        "dim_feedforward=2048"
      ],
      "metadata": {
        "id": "0-NQTLO1O6SO"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, vocab_size=5000, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(vocab_size, d_model)\n",
        "        position = torch.arange(0, vocab_size, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2).float()\n",
        "            * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, : x.size(1), :]\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "1xfcScg_4pWF"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderClassifier(nn.Module):\n",
        "  def __init__(self,  vocab_size, embed_dim, num_layers, num_heads, output_size):\n",
        "    super().__init__()\n",
        "    self.emb = nn.Embedding(vocab_size, d_model)\n",
        "    self.pos_encoder = PositionalEncoding(d_model=d_model, vocab_size=tokenizer.n_vocab)\n",
        "    self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=num_heads,dim_feedforward=dim_feedforward ,batch_first=True)\n",
        "    self.encoder = nn.TransformerEncoder(encoder_layer=self.encoder_layer, num_layers=num_layers)\n",
        "\n",
        "    self.linear = nn.Linear(d_model, output_size)\n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.emb(x) * math.sqrt(d_model)\n",
        "    x = self.pos_encoder(x)\n",
        "    x = self.encoder(x)\n",
        "    x = self.dropout(x)\n",
        "    #x = x.max(dim=1)[0]\n",
        "    #print(x)\n",
        "    #x = x.mean(dim=1)\n",
        "    x = x[:, 0, :]\n",
        "    out = self.linear(x)\n",
        "\n",
        "    return out\n",
        "\n",
        "modelT = EncoderClassifier(tokenizer.n_vocab, embed_dim=EMBED_DIM, num_layers=NUM_ENCODER_LAYERS, num_heads=NUM_HEADS, output_size=4).to(device)\n",
        "#modelT"
      ],
      "metadata": {
        "id": "zLOr5fm9OzEL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(modelT.parameters(), lr=1e-4 )"
      ],
      "metadata": {
        "id": "TGS8ciCLRNVg"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "\n",
        "modelT.train()\n",
        "for epoch in range(epochs):\n",
        "  total_loss = 0\n",
        "\n",
        "  for text, label in train_loader:\n",
        "    text, label = text.to(device), label.to(device)\n",
        "\n",
        "    outputs = modelT(text)\n",
        "    loss = loss_fn(outputs, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zmplgUeQlS6",
        "outputId": "6cd7c3fb-5ce8-49ff-83d0-9e720fd8d424"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30, Loss: 1.0732\n",
            "Epoch 2/30, Loss: 1.0731\n",
            "Epoch 3/30, Loss: 1.0693\n",
            "Epoch 4/30, Loss: 1.0540\n",
            "Epoch 5/30, Loss: 1.0719\n",
            "Epoch 6/30, Loss: 1.0716\n",
            "Epoch 7/30, Loss: 1.0684\n",
            "Epoch 8/30, Loss: 1.0497\n",
            "Epoch 9/30, Loss: 1.0824\n",
            "Epoch 10/30, Loss: 1.0637\n",
            "Epoch 11/30, Loss: 1.0532\n",
            "Epoch 12/30, Loss: 1.0362\n",
            "Epoch 13/30, Loss: 1.0500\n",
            "Epoch 14/30, Loss: 1.0422\n",
            "Epoch 15/30, Loss: 1.0493\n",
            "Epoch 16/30, Loss: 1.0354\n",
            "Epoch 17/30, Loss: 1.0473\n",
            "Epoch 18/30, Loss: 1.0580\n",
            "Epoch 19/30, Loss: 1.0315\n",
            "Epoch 20/30, Loss: 1.0372\n",
            "Epoch 21/30, Loss: 1.0456\n",
            "Epoch 22/30, Loss: 1.0267\n",
            "Epoch 23/30, Loss: 1.0384\n",
            "Epoch 24/30, Loss: 1.0208\n",
            "Epoch 25/30, Loss: 1.0220\n",
            "Epoch 26/30, Loss: 1.0126\n",
            "Epoch 27/30, Loss: 1.0094\n",
            "Epoch 28/30, Loss: 1.0160\n",
            "Epoch 29/30, Loss: 1.0278\n",
            "Epoch 30/30, Loss: 1.0406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 350\n",
        "text = tokenizer.encode(train_texts[idx])\n",
        "input_tens = torch.tensor(text, dtype=torch.long).unsqueeze(0).to(device)\n",
        "out = modelT(input_tens)\n",
        "max_index_argmax = out.argmax()\n",
        "print(max_index_argmax)\n",
        "print(label_map[train_status[idx]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRudJriLSJIh",
        "outputId": "467c5825-c14c-42b3-a43f-f607460b5657"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1, device='cuda:0')\n",
            "1\n"
          ]
        }
      ]
    }
  ]
}